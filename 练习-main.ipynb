{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from testloader import iris_dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--num_classes', type=int, default=100, help='the number of classes')\n",
    "# parser.add_argument('--epochs', type=int, default=20, help='the number of training epoch')\n",
    "# parser.add_argument('--batch_size', type=int, default=16, help='batch_size for training')\n",
    "# parser.add_argument('--lr', type=float, default=0.005, help='star learning rate')   \n",
    "# parser.add_argument('--data_path', type=str, default=\"神经网络实现鸢尾花分类\\Iris_data.txt\") \n",
    "# parser.add_argument('--device', default='cuda', help='device id (i.e. 0 or 0,1 or cpu)')\n",
    "# opt = parser.parse_args()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuralnetwork(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Neuralnetwork,self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150images were found in the dataset\n",
      "Training set data size: 112 ,Validating set data size: 30 ,Testing set data size: 15\n"
     ]
    }
   ],
   "source": [
    "custom_dataset = iris_dataload( \"./Iris_data.txt\") \n",
    "train_size = int(len(custom_dataset)*0.7)\n",
    "validate_size = int(len(custom_dataset)*0.2)\n",
    "test_size = len(custom_dataset) - train_size -validate_size\n",
    "train_dataset,validate_dataset,test_dataset = torch.utils.data.random_split(custom_dataset,[train_size,validate_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=16,shuffle=False)\n",
    "validate_loader= DataLoader(validate_dataset,batch_size=1,shuffle=False)\n",
    "test_loader= DataLoader(test_dataset,batch_size=1,shuffle=False)\n",
    "print(\"Training set data size:\", len(train_loader)*16, \",Validating set data size:\", len(validate_loader), \",Testing set data size:\", len(test_loader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义推理过程，返回准确率，用于验证阶段和测试阶段\n",
    "def infer(model,dataset,device):\n",
    "    model.eval()\n",
    "    acc_num =0.0\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            datas,labels = data\n",
    "            outputs = model(datas.to(device))\n",
    "            predict_y = torch.max(outputs,dim=1)[1]\n",
    "            acc_num += torch.eq(predict_y,labels.to(device)).sum().item()\n",
    "    accuratcy = acc_num/len(dataset)\n",
    "    return accuratcy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练，验证，测试阶段\n",
    "def main():\n",
    "\n",
    "    model = Neuralnetwork(4,12,6,3).to(device)\n",
    "    loss_fuction = nn.CrossEntropyLoss()\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(pg, lr = 0.001)\n",
    "\n",
    "    #定义模型权重存储地址\n",
    "    save_path = os.path.join(os.getcwd(),'test_results/weights')\n",
    "    if os.path.exists(save_path) is False:\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    epochs = 20\n",
    "    #开始训练过程\n",
    "    for epoch in range(epochs):\n",
    "        ############################################################## train ######################################################\n",
    "        model.train()\n",
    "        acc_num = torch.zeros(1).to(device)\n",
    "        sample_num = 0\n",
    "        train_bar = tqdm(train_loader,file =sys.stdout,ncols = 100)\n",
    "        for datas in train_bar:\n",
    "            data,label = datas\n",
    "            label = label.squeeze(-1)\n",
    "            sample_num += data.shape[0]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data.to(device))# output_shape: [batch_size, num_classes]\n",
    "            pred_class = torch.max(outputs,dim=1)[1]# torch.max 返回值是一个tuple，第一个元素是max值，第二个元素是max值的索引。\n",
    "            acc_num += torch.eq(pred_class,label.to(device)).sum()\n",
    "\n",
    "            loss = loss_fuction(outputs,label.to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_acc = acc_num.item()/sample_num\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch+1,epochs,loss)\n",
    "        ############################################################## validate ###################################################### \n",
    "        val_acc = infer(model = model ,dataset=validate_loader,device=device)\n",
    "        print('[epoch %d] train_loss: %.3f  train_acc: %.3f  val_accuracy: %.3f' %  (epoch + 1, loss, train_acc, val_acc))   \n",
    "        torch.save(model.state_dict(),os.path.join(save_path,\"test_NN_pth\"))\n",
    "\n",
    "        train_acc =0.0\n",
    "        val_acc = 0.0\n",
    "    print('完成')\n",
    "    ################################################################# test ############################################################         \n",
    "    test_acc = infer(model = model,dataset=test_loader,device=device)\n",
    "    print('test_accuracy:%.3f'%(test_acc))\n",
    "\n",
    "if __name__==\"main\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/20] loss:1.167: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 595.25it/s]\n",
      "[epoch 1] train_loss: 1.167  train_acc: 0.314  val_accuracy: 0.367\n",
      "train epoch[2/20] loss:1.131: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 466.74it/s]\n",
      "[epoch 2] train_loss: 1.131  train_acc: 0.352  val_accuracy: 0.367\n",
      "train epoch[3/20] loss:1.098: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 999.97it/s]\n",
      "[epoch 3] train_loss: 1.098  train_acc: 0.362  val_accuracy: 0.367\n",
      "train epoch[4/20] loss:1.068: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 874.96it/s]\n",
      "[epoch 4] train_loss: 1.068  train_acc: 0.362  val_accuracy: 0.367\n",
      "train epoch[5/20] loss:1.040: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 777.53it/s]\n",
      "[epoch 5] train_loss: 1.040  train_acc: 0.362  val_accuracy: 0.367\n",
      "train epoch[6/20] loss:1.015: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 699.93it/s]\n",
      "[epoch 6] train_loss: 1.015  train_acc: 0.362  val_accuracy: 0.367\n",
      "train epoch[7/20] loss:0.990: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 700.03it/s]\n",
      "[epoch 7] train_loss: 0.990  train_acc: 0.410  val_accuracy: 0.600\n",
      "train epoch[8/20] loss:0.967: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 700.07it/s]\n",
      "[epoch 8] train_loss: 0.967  train_acc: 0.667  val_accuracy: 0.667\n",
      "train epoch[9/20] loss:0.943: 100%|██████████████████████████████████| 7/7 [00:00<00:00, 700.05it/s]\n",
      "[epoch 9] train_loss: 0.943  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[10/20] loss:0.919: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 699.95it/s]\n",
      "[epoch 10] train_loss: 0.919  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[11/20] loss:0.895: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 636.34it/s]\n",
      "[epoch 11] train_loss: 0.895  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[12/20] loss:0.870: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 777.75it/s]\n",
      "[epoch 12] train_loss: 0.870  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[13/20] loss:0.845: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 636.34it/s]\n",
      "[epoch 13] train_loss: 0.845  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[14/20] loss:0.819: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 700.00it/s]\n",
      "[epoch 14] train_loss: 0.819  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[15/20] loss:0.792: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 636.20it/s]\n",
      "[epoch 15] train_loss: 0.792  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[16/20] loss:0.766: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 777.77it/s]\n",
      "[epoch 16] train_loss: 0.766  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[17/20] loss:0.739: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 699.92it/s]\n",
      "[epoch 17] train_loss: 0.739  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[18/20] loss:0.712: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 999.94it/s]\n",
      "[epoch 18] train_loss: 0.712  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[19/20] loss:0.685: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 874.85it/s]\n",
      "[epoch 19] train_loss: 0.685  train_acc: 0.686  val_accuracy: 0.667\n",
      "train epoch[20/20] loss:0.660: 100%|█████████████████████████████████| 7/7 [00:00<00:00, 699.95it/s]\n",
      "[epoch 20] train_loss: 0.660  train_acc: 0.686  val_accuracy: 0.667\n",
      "完成\n",
      "test_accuracy:0.533\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
